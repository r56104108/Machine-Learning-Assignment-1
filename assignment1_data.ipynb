{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "DXqdT__w2eAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0No7fP71Ins"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Assignment-1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9loOSXnD1ON4",
        "outputId": "a0a7f037-c5f3-4db6-b636-d42516be3c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Assignment-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "df2 = df\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9WR5Wgr1P43",
        "outputId": "ff1cf133-69f4-4113-8d40-e9eb4c282fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID Diagnosis      3      4       5       6        7        8  \\\n",
              "0      842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760   \n",
              "1      842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864   \n",
              "2    84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990   \n",
              "3    84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390   \n",
              "4    84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
              "..        ...       ...    ...    ...     ...     ...      ...      ...   \n",
              "564    926424         M  21.56  22.39  142.00  1479.0  0.11100  0.11590   \n",
              "565    926682         M  20.13  28.25  131.20  1261.0  0.09780  0.10340   \n",
              "566    926954         M  16.60  28.08  108.30   858.1  0.08455  0.10230   \n",
              "567    927241         M  20.60  29.33  140.10  1265.0  0.11780  0.27700   \n",
              "568     92751         B   7.76  24.54   47.92   181.0  0.05263  0.04362   \n",
              "\n",
              "           9       10  ...      23     24      25      26       27       28  \\\n",
              "0    0.30010  0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560   \n",
              "1    0.08690  0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660   \n",
              "2    0.19740  0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450   \n",
              "3    0.24140  0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630   \n",
              "4    0.19800  0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500   \n",
              "..       ...      ...  ...     ...    ...     ...     ...      ...      ...   \n",
              "564  0.24390  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130   \n",
              "565  0.14400  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220   \n",
              "566  0.09251  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940   \n",
              "567  0.35140  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810   \n",
              "568  0.00000  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444   \n",
              "\n",
              "         29      30      31       32  \n",
              "0    0.7119  0.2654  0.4601  0.11890  \n",
              "1    0.2416  0.1860  0.2750  0.08902  \n",
              "2    0.4504  0.2430  0.3613  0.08758  \n",
              "3    0.6869  0.2575  0.6638  0.17300  \n",
              "4    0.4000  0.1625  0.2364  0.07678  \n",
              "..      ...     ...     ...      ...  \n",
              "564  0.4107  0.2216  0.2060  0.07115  \n",
              "565  0.3215  0.1628  0.2572  0.06637  \n",
              "566  0.3403  0.1418  0.2218  0.07820  \n",
              "567  0.9387  0.2650  0.4087  0.12400  \n",
              "568  0.0000  0.0000  0.2871  0.07039  \n",
              "\n",
              "[569 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f47eb6a-1941-4afc-b241-5a784c9fab8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f47eb6a-1941-4afc-b241-5a784c9fab8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f47eb6a-1941-4afc-b241-5a784c9fab8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f47eb6a-1941-4afc-b241-5a784c9fab8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 'M' to 1 and 'B' to -1\n",
        "df2['Diagnosis'] = [-1 if x == 'B' else 1 for x in df2['Diagnosis']]\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SezsdSs1Rdy",
        "outputId": "ccf01332-209b-4509-c65a-83b3f0afaa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID  Diagnosis      3      4       5       6        7        8  \\\n",
              "0      842302          1  17.99  10.38  122.80  1001.0  0.11840  0.27760   \n",
              "1      842517          1  20.57  17.77  132.90  1326.0  0.08474  0.07864   \n",
              "2    84300903          1  19.69  21.25  130.00  1203.0  0.10960  0.15990   \n",
              "3    84348301          1  11.42  20.38   77.58   386.1  0.14250  0.28390   \n",
              "4    84358402          1  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
              "..        ...        ...    ...    ...     ...     ...      ...      ...   \n",
              "564    926424          1  21.56  22.39  142.00  1479.0  0.11100  0.11590   \n",
              "565    926682          1  20.13  28.25  131.20  1261.0  0.09780  0.10340   \n",
              "566    926954          1  16.60  28.08  108.30   858.1  0.08455  0.10230   \n",
              "567    927241          1  20.60  29.33  140.10  1265.0  0.11780  0.27700   \n",
              "568     92751         -1   7.76  24.54   47.92   181.0  0.05263  0.04362   \n",
              "\n",
              "           9       10  ...      23     24      25      26       27       28  \\\n",
              "0    0.30010  0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560   \n",
              "1    0.08690  0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660   \n",
              "2    0.19740  0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450   \n",
              "3    0.24140  0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630   \n",
              "4    0.19800  0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500   \n",
              "..       ...      ...  ...     ...    ...     ...     ...      ...      ...   \n",
              "564  0.24390  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130   \n",
              "565  0.14400  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220   \n",
              "566  0.09251  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940   \n",
              "567  0.35140  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810   \n",
              "568  0.00000  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444   \n",
              "\n",
              "         29      30      31       32  \n",
              "0    0.7119  0.2654  0.4601  0.11890  \n",
              "1    0.2416  0.1860  0.2750  0.08902  \n",
              "2    0.4504  0.2430  0.3613  0.08758  \n",
              "3    0.6869  0.2575  0.6638  0.17300  \n",
              "4    0.4000  0.1625  0.2364  0.07678  \n",
              "..      ...     ...     ...      ...  \n",
              "564  0.4107  0.2216  0.2060  0.07115  \n",
              "565  0.3215  0.1628  0.2572  0.06637  \n",
              "566  0.3403  0.1418  0.2218  0.07820  \n",
              "567  0.9387  0.2650  0.4087  0.12400  \n",
              "568  0.0000  0.0000  0.2871  0.07039  \n",
              "\n",
              "[569 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7117b991-890f-4139-9ce2-d0dd6205dc46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>-1</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7117b991-890f-4139-9ce2-d0dd6205dc46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7117b991-890f-4139-9ce2-d0dd6205dc46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7117b991-890f-4139-9ce2-d0dd6205dc46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.drop('ID', 1)\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_WppTF21jeo",
        "outputId": "f1cc68af-fe86-413a-8905-fdf264a27afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Diagnosis      3      4       5       6        7        8        9  \\\n",
              "0            1  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
              "1            1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
              "2            1  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
              "3            1  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
              "4            1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
              "..         ...    ...    ...     ...     ...      ...      ...      ...   \n",
              "564          1  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
              "565          1  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
              "566          1  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
              "567          1  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
              "568         -1   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
              "\n",
              "          10      11  ...      23     24      25      26       27       28  \\\n",
              "0    0.14710  0.2419  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560   \n",
              "1    0.07017  0.1812  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660   \n",
              "2    0.12790  0.2069  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450   \n",
              "3    0.10520  0.2597  ...  14.910  26.50   98.87   567.7  0.20980  0.86630   \n",
              "4    0.10430  0.1809  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500   \n",
              "..       ...     ...  ...     ...    ...     ...     ...      ...      ...   \n",
              "564  0.13890  0.1726  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130   \n",
              "565  0.09791  0.1752  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220   \n",
              "566  0.05302  0.1590  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940   \n",
              "567  0.15200  0.2397  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810   \n",
              "568  0.00000  0.1587  ...   9.456  30.37   59.16   268.6  0.08996  0.06444   \n",
              "\n",
              "         29      30      31       32  \n",
              "0    0.7119  0.2654  0.4601  0.11890  \n",
              "1    0.2416  0.1860  0.2750  0.08902  \n",
              "2    0.4504  0.2430  0.3613  0.08758  \n",
              "3    0.6869  0.2575  0.6638  0.17300  \n",
              "4    0.4000  0.1625  0.2364  0.07678  \n",
              "..      ...     ...     ...      ...  \n",
              "564  0.4107  0.2216  0.2060  0.07115  \n",
              "565  0.3215  0.1628  0.2572  0.06637  \n",
              "566  0.3403  0.1418  0.2218  0.07820  \n",
              "567  0.9387  0.2650  0.4087  0.12400  \n",
              "568  0.0000  0.0000  0.2871  0.07039  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83746218-f887-4230-ab35-d9734b68bb5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>...</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>-1</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83746218-f887-4230-ab35-d9734b68bb5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83746218-f887-4230-ab35-d9734b68bb5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83746218-f887-4230-ab35-d9734b68bb5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign X as a DataFrame of features and y as a Series of the outcome variable\n",
        "y = df2['Diagnosis']\n",
        "X = df2.drop('Diagnosis', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht9ymj3P163y",
        "outputId": "10de292c-1ea2-44f0-ccec-0d9bf1bf6315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Pandas Dataframe to NumPy Array\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "metadata": {
        "id": "OaRDbABR2HIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2 (Perceptron)"
      ],
      "metadata": {
        "id": "6kIcSnUZ2mxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = X.shape\n",
        "weights = np.zeros(n_features)"
      ],
      "metadata": {
        "id": "uogX3rAe2izE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(X, y, iterations):\n",
        "    for _ in range(iterations):\n",
        "        for idx, x_i in enumerate(X):\n",
        "            linear_output = np.dot(x_i, weights)\n",
        "            if linear_output >= 0:\n",
        "                y_predicted = 1\n",
        "            else:\n",
        "                y_predicted = -1\n",
        "\n",
        "            if y_predicted != y[idx]:\n",
        "                weights += y_predicted * x_i"
      ],
      "metadata": {
        "id": "XrHI5HLL46is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron class\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, n_iters=1000):\n",
        "        self.n_iters = n_iters\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "\n",
        "        y_ = np.array([1 if i > 0 else -1 for i in y])\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "\n",
        "            for idx, x_i in enumerate(X):\n",
        "\n",
        "                linear_output = np.dot(x_i, self.weights)\n",
        "                y_predicted = self.activation_func(linear_output)\n",
        "\n",
        "                # Perceptron update rule\n",
        "                if y_predicted != y_[idx]:\n",
        "                    self.weights += y_predicted * x_i\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights)\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "        return y_predicted\n",
        "\n",
        "    def _unit_step_func(self, x):\n",
        "        return np.where(x >= 0, 1, -1)"
      ],
      "metadata": {
        "id": "5ls8VSbJ-Dbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "X_length, X_columns = X.shape\n",
        "train_size = (int)(X_length * 0.8)\n",
        "\n",
        "X_train = X[0:train_size]\n",
        "X_test = X[train_size:]\n",
        "y_train = y[0:train_size]\n",
        "y_test =  y[train_size:]\n",
        "\n",
        "p = Perceptron(n_iters=1000)\n",
        "p.fit(X_train, y_train)\n",
        "predictions_perceptron = p.predict(X_test)\n",
        "print(\"Perceptron classification accuracy:\", accuracy(y_test, predictions_perceptron))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jAlOT5s_P2V",
        "outputId": "a5c0a2a4-158e-4106-edba-1c4a76de133e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron classification accuracy: 0.22807017543859648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3 (Linear Regression Binary Classification)"
      ],
      "metadata": {
        "id": "VgZ5GmE520Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # gradient descent\n",
        "        for _ in range(self.n_iters):\n",
        "            y_predicted = np.dot(X, self.weights) + self.bias\n",
        "            # compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            # update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_approximated = np.dot(X, self.weights) + self.bias\n",
        "        y_approximated = np.array([1 if i >= 0 else -1 for i in y_approximated])\n",
        "        return y_approximated\n"
      ],
      "metadata": {
        "id": "eVWuote1_ptD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LinearRegression(learning_rate=0.01, n_iters=1000)\n",
        "regressor.fit(X_train, y_train)\n",
        "predictions_linear_regression = regressor.predict(X_test)\n",
        "print(\"Linear Regression classification accuracy:\", accuracy(y_test, predictions_linear_regression))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMWDBUJMaty",
        "outputId": "64ae834b-3ca3-4f0f-f871-5fbbcf3e7146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression classification accuracy: 0.7719298245614035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in subtract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4 (Voted Perceptron)"
      ],
      "metadata": {
        "id": "ReAVe-ov20SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to join relevant information all together\n",
        "def join(w, b, time_alive):\n",
        "    perceptron = []\n",
        "    perceptron.append(w)\n",
        "    perceptron.append(b)\n",
        "    perceptron.append(time_alive)\n",
        "    return perceptron\n",
        "\n",
        "\n",
        "# Utility function to extract data from perceptron's list\n",
        "def extract_data(perceptron):\n",
        "    w = perceptron[0]\n",
        "    b = perceptron[1]\n",
        "    weight = perceptron[2]\n",
        "    return w, b, weight\n",
        "\n",
        "# Voted perceptron train function\n",
        "def voted_perceptron_train(data, labels, max_iter):\n",
        "    w = np.zeros(len(data[0]))\n",
        "    b = 0\n",
        "    time_alive = 1\n",
        "    perceptrons = []\n",
        "    for iter in range(max_iter):\n",
        "        for i in range(len(data)):\n",
        "            x = data[i]\n",
        "            y = labels[i]\n",
        "            if y * (np.dot(x, w) + b) <= 0:\n",
        "                perceptrons.append(join(w, b, time_alive))\n",
        "                time_alive = 1\n",
        "                delta = np.multiply(y, x)\n",
        "                w = np.add(w, delta)\n",
        "                b += y\n",
        "            else:\n",
        "                time_alive += 1\n",
        "    perceptrons.append(join(w, b, time_alive))\n",
        "    return perceptrons\n",
        "\n",
        "\n",
        "# Voted perceptron prediction function\n",
        "def voted_perceptron_predict(perceptrons, example):\n",
        "    sum = 0\n",
        "    for perceptron in perceptrons:\n",
        "        w, b, weight = extract_data(perceptron)\n",
        "        sum += weight * np.sign(np.dot(w, example))\n",
        "    return np.sign(sum)"
      ],
      "metadata": {
        "id": "QSrZTEZwPzv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictions_result(X_test):\n",
        "    predictions = np.empty(0)\n",
        "    for x in X_test:\n",
        "        predictions = np.append(predictions, voted_perceptron_predict(voted_perceptrons, x))\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "39xBQNgOXHr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voted_perceptrons = voted_perceptron_train(X_train, y_train, 1000)\n",
        "predictions_voted_perceptron = predictions_result(X_test)\n",
        "print(\"Voted Perceptron classification accuracy:\", accuracy(y_test, predictions_voted_perceptron))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11k5ltPCSalu",
        "outputId": "66b5c7df-1e0a-4d12-a133-a0b8be8a44eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voted Perceptron classification accuracy: 0.9298245614035088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5 (SVM)"
      ],
      "metadata": {
        "id": "HvjPW6q320Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM:\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
        "                if condition:\n",
        "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
        "                else:\n",
        "                    self.w -= self.lr * (\n",
        "                        2 * self.lambda_param * self.w - np.dot(x_i, y_[idx])\n",
        "                    )\n",
        "                    self.b -= self.lr * y_[idx]\n",
        "\n",
        "    def predict(self, X):\n",
        "        approx = np.dot(X, self.w) - self.b\n",
        "        return np.sign(approx)\n"
      ],
      "metadata": {
        "id": "i3U60hkUYhSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVM()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions_svm = clf.predict(X_test)\n",
        "print(\"SVM classification accuracy:\", accuracy(y_test, predictions_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NChtfdmoSzsz",
        "outputId": "c6c0291c-d36d-46de-8e49-413e26e18fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 0.9210526315789473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.w, clf.b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eveb2sMrS4bA",
        "outputId": "ff012491-0aa9-4ffa-81f8-37805a3dfa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.11184732e+00 -5.04411564e-01 -1.97742397e+01 -3.53587585e+00\n",
            " -1.17155555e-03  1.49314334e-01  2.51738140e-01  9.83937755e-02\n",
            " -1.90818477e-02 -1.17281965e-02 -2.46230978e-02  1.55066293e-01\n",
            "  4.65450957e-01  7.66400536e+00  3.86533697e-03  4.09080481e-02\n",
            "  5.67387558e-02  1.17657876e-02  9.18493617e-03  2.12657828e-03\n",
            " -4.35454234e+00  5.55301769e-01 -1.64574304e+01  6.85902889e+00\n",
            "  1.32188313e-02  4.87573280e-01  6.43206069e-01  1.71756649e-01\n",
            "  3.80600165e-02  1.52858537e-02] 5.086000000000033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6 (Soft Margin SVM)"
      ],
      "metadata": {
        "id": "K_NqLpLP21N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxopt\n",
        "\n",
        "\n",
        "class SVMSoftMargin():\n",
        "\n",
        "    def __init__(self, C: float):\n",
        "        self.C = C\n",
        "        self._w = None\n",
        "        self._b = None\n",
        "\n",
        "    def train(self, X: np.ndarray, y: np.ndarray):\n",
        "        n_samples, _ = X.shape\n",
        "        # compute inputs for cvxopt solver\n",
        "        K = (X * y[:, np.newaxis]).T\n",
        "        P = cvxopt.matrix(K.T.dot(K)) # P has shape n*n\n",
        "        q = cvxopt.matrix(-1 * np.ones(n_samples)) # q has shape n*1\n",
        "        G = cvxopt.matrix(np.concatenate((-1*np.identity(n_samples), np.identity(n_samples)), axis=0))\n",
        "        h = cvxopt.matrix(np.concatenate((np.zeros(n_samples), self.C*np.ones(n_samples)), axis=0))\n",
        "        A = cvxopt.matrix(1.0 * y, (1, n_samples))\n",
        "        b = cvxopt.matrix(0.0)\n",
        "        # solve quadratic programming\n",
        "        cvxopt.solvers.options['show_progress'] = False\n",
        "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "        _lambda = np.ravel(solution['x'])\n",
        "        # find support vectors\n",
        "        S = np.where((_lambda > 1e-10) & (_lambda <= self.C))[0]\n",
        "        self._w = K[:, S].dot(_lambda[S])\n",
        "        M = np.where((_lambda > 1e-10) & (_lambda < self.C))[0]\n",
        "        self._b = np.mean(y[M] - X[M, :].dot(self._w))\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Return +1 for positive class and -1 for negative class.\n",
        "        \"\"\"\n",
        "        results = np.sign(X.dot(self._w) + self._b)\n",
        "        results[results == 0] = 1\n",
        "        return results"
      ],
      "metadata": {
        "id": "i3Qo1GR8HsPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_soft_margin_svm = SVMSoftMargin(5.0)\n",
        "clf_soft_margin_svm.train(X_train, y_train)\n",
        "predictions_soft_margin_svm = clf_soft_margin_svm.predict(X_test)\n",
        "print(\"Soft Margin SVM classification accuracy:\", accuracy(y_test, predictions_soft_margin_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kon4DioZHz95",
        "outputId": "ef26a166-02d2-480e-a04b-2dad3c086c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft Margin SVM classification accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7 (Scikit-learn SVM)"
      ],
      "metadata": {
        "id": "CNciBmtY245H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import support vector classifier \n",
        "# \"Support Vector Classifier\"\n",
        "from sklearn.svm import SVC  \n",
        "clf_sklearn = SVC(kernel='linear') \n",
        "  \n",
        "# fitting x samples and y classes \n",
        "clf_sklearn.fit(X_train, y_train)\n",
        "predictions_sklearn = clf_sklearn.predict(X_test)\n",
        "print(\"ScikitLearn SVM classification accuracy:\", accuracy(y_test, predictions_sklearn))"
      ],
      "metadata": {
        "id": "O7A5kzJy2-jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dcc786-34d3-4f41-de1d-ef9344196fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ScikitLearn SVM classification accuracy: 0.9385964912280702\n"
          ]
        }
      ]
    }
  ]
}